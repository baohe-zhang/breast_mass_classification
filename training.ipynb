{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "IS_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDSM(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, label_file, transform):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_list = []\n",
    "        \n",
    "        def process_line(line):\n",
    "            img_name, label = line.strip().split(' ')\n",
    "            label = int(label)\n",
    "            return img_name, label\n",
    "        \n",
    "        with open(os.path.join(root, label_file), 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                self.image_list.append(process_line(line))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name, label = self.image_list[idx]\n",
    "        img = Image.open(os.path.join(self.root, img_name)).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and std in advance\n",
    "\n",
    "def cal_mean_std():\n",
    "    import numpy as np\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "    train_dataset = DDSM(root, 'images/dataset-v2/train.txt', transforms.Compose([transforms.Resize(224),\n",
    "                                                                                  transforms.ToTensor()],))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    data_mean = []\n",
    "    data_std = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        np_images = batch[0].numpy()\n",
    "        batch_mean = np.mean(np_images, axis=(0, 2, 3))\n",
    "        batch_std = np.std(np_images, axis=(0, 2, 3))\n",
    "        data_mean.append(batch_mean)\n",
    "        data_std.append(batch_std)\n",
    "\n",
    "    data_mean = np.array(data_mean).mean(axis=0)\n",
    "    data_std = np.array(data_std).mean(axis=0)\n",
    "\n",
    "    print('mean: {}'.format(data_mean))\n",
    "    print('std: {}'.format(data_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "root = './'\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.504, 0.504, 0.504], std=[0.172, 0.172, 0.172])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(360),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "train_dataset = DDSM(root, 'images/dataset-v2/train.txt', augmented_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_dataset = DDSM(root, 'images/dataset-v2/test.txt', transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNet, self).__init__()\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.fc_net = nn.Sequential(\n",
    "            nn.Linear(in_features=288, out_features=512),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.Linear(in_features=128, out_features=2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_net(x)\n",
    "        x = x.view(x.size(0), -1) # batch_size x image\n",
    "        x = self.fc_net(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline CNN\n",
    "\n",
    "def get_basenet():\n",
    "    model = BaseNet()\n",
    "\n",
    "    if IS_GPU:\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet\n",
    "\n",
    "def get_alexnet(pretrained=False):\n",
    "    import torchvision.models as models\n",
    "    import torch.nn as nn\n",
    "\n",
    "    model = models.__dict__['alexnet'](pretrained=False)\n",
    "\n",
    "    model.classifier._modules['6'] = nn.Linear(4096, 2)\n",
    "\n",
    "    if IS_GPU:\n",
    "        model.features = torch.nn.DataParallel(model.features)\n",
    "        model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18\n",
    "\n",
    "def get_resnet(pretrained=False):\n",
    "    import torchvision.models as models\n",
    "    import torch.nn as nn\n",
    "\n",
    "    model = models.__dict__['resnet18'](pretrained=pretrained)\n",
    "\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "    if IS_GPU:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "\n",
    "def get_optimizer(model, lr=0.01, momentum=0.9):\n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "def train_model(model, optimizer, start_epoch=1, epoch_num=20, filename=None, save_model_name=None):\n",
    "    import time\n",
    "\n",
    "    # filename = 'resnet-no-tl.txt'\n",
    "\n",
    "    start_ts = time.time()\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + epoch_num):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "\n",
    "        sample_count = 0\n",
    "        correct_count = 0\n",
    "\n",
    "        for i, samples in enumerate(train_loader):\n",
    "            images, labels = samples\n",
    "            if IS_GPU:\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            sample_count += len(labels)\n",
    "            correct_count += torch.sum(preds == labels).item()\n",
    "\n",
    "        print('Time: {}'.format(int(time.time() - start_ts)))\n",
    "\n",
    "        train_acc = correct_count / sample_count\n",
    "        test_acc, precision, recall, F1 = evaluate(model, test_loader, epoch)\n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_epoch = epoch\n",
    "\n",
    "        print('Epoch {} '.format(epoch) + 'tarin accuracy: ' + str(train_acc))\n",
    "        print('Epoch {} '.format(epoch) + 'loss: ' + str(epoch_loss))\n",
    "        print('Epoch {} '.format(best_epoch) + 'has the best test accuracy: ' + str(best_test_acc))\n",
    "        print()\n",
    "\n",
    "        if filename:\n",
    "            with open('./evaluation/{}'.format(filename), 'a') as f:\n",
    "                f.write('Evaluate epoch {} '.format(epoch) + 'accuracy: ' + str(test_acc) + '\\n')\n",
    "                f.write('Evaluate epoch {} '.format(epoch) + 'precision: ' + str(precision) + '\\n')\n",
    "                f.write('Evaluate epoch {} '.format(epoch) + 'recall: ' + str(recall) + '\\n')\n",
    "                f.write('Evaluate epoch {} '.format(epoch) + 'F1: ' + str(F1) + '\\n')\n",
    "                f.write('epoch {} '.format(epoch) + 'tarin accuracy: ' + str(train_acc) + '\\n')\n",
    "                f.write('epoch {} '.format(epoch) + 'loss: ' + str(epoch_loss) + '\\n')\n",
    "                f.write('epoch {} '.format(best_epoch) + 'has the best test acc: ' + str(best_test_acc) + '\\n\\n')\n",
    "                \n",
    "    if save_model_name:\n",
    "        torch.save(model, './models/{}.pth'.format(save_model_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_resnet()\n",
    "# optimizer = get_optimizer(model)\n",
    "# train_model(model, optimizer, start_epoch=451, epoch_num=100, filename='resnet-no-tl.txt')\n",
    "train_model(model, optimizer, start_epoch=451, epoch_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_resnet()\n",
    "optimizer = get_optimizer(model)\n",
    "train_model(model, optimizer, start_epoch=1, epoch_num=400, filename='resnet-no-tl.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, optimizer, start_epoch=601, epoch_num=50, filename='resnet-no-tl.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_basenet()\n",
    "# optimizer = get_optimizer(model, lr=0.01)\n",
    "# train_model(model, optimizer, start_epoch=101, epoch_num=100, filename='basenet-lr-1-2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def evaluate(model, data_loader, epoch):\n",
    "    with torch.no_grad():\n",
    "        sample_count = 0\n",
    "        correct_count = 0\n",
    "        \n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        \n",
    "        accuracy = 0.0\n",
    "        precision = 0.0\n",
    "        recall = 0.0\n",
    "        F1 = 0.0\n",
    "\n",
    "        for i, samples in enumerate(data_loader):\n",
    "            images, labels = samples\n",
    "\n",
    "            if IS_GPU:\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            sample_count += len(labels)\n",
    "            correct_count += torch.sum(preds == labels).item()\n",
    "            \n",
    "            for idx in range(len(labels)):\n",
    "                if labels[idx] == 1 and preds[idx] == 1:\n",
    "                    TP += 1\n",
    "                if labels[idx] == 1 and preds[idx] == 0:\n",
    "                    FN += 1\n",
    "                if labels[idx] == 0 and preds[idx] == 1:\n",
    "                    FP += 1\n",
    "        \n",
    "        try:\n",
    "            accuracy = correct_count / sample_count\n",
    "            precision = TP / (TP + FP)\n",
    "            recall = TP / (TP + FN)\n",
    "            F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "            print('Evaluate epoch {} accuracy: '.format(epoch) + str(accuracy))\n",
    "            print('Evaluate epoch {} precision: '.format(epoch) + str(precision))\n",
    "            print('Evaluate epoch {} recall: '.format(epoch) + str(recall))\n",
    "            print('Evaluate epoch {} F1: '.format(epoch) + str(F1))\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "        \n",
    "        return accuracy, precision, recall, F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \n",
    "    from torch.autograd import Variable\n",
    "    \n",
    "    \"\"\"\n",
    "    使用模型图像(image)X和标记(label)y计算正确类的saliency map.\n",
    "\n",
    "    输入:\n",
    "    - X: 输入图像; Tensor of shape (N, 3, H, W)\n",
    "    - y: 对应X的标记; LongTensor of shape (N,)\n",
    "    - model: 一个预先训练好的神经网络模型用于计算X.\n",
    "\n",
    "    返回值:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "\n",
    "    # Wrap the input tensors in Variables\n",
    "    X_var = Variable(X, requires_grad=True)\n",
    "    y_var = Variable(y)\n",
    "    saliency = None\n",
    "    ##############################################################################\n",
    "    #\n",
    "    # 首先进行前向操作，将输入图像pass through已经训练好的model，再进行反向操作，\n",
    "    # 从而得到对应图像,正确分类分数的梯度\n",
    "    # \n",
    "    ##############################################################################\n",
    "\n",
    "    # 前向操作\n",
    "    scores = model(X_var)\n",
    "\n",
    "    # 得到正确类的分数，scores为[5]的Tensor\n",
    "    scores = scores.gather(1, y_var.view(-1, 1)).squeeze() \n",
    "\n",
    "    #反向计算，从输出的分数到输入的图像进行一系列梯度计算\n",
    "    scores.backward(torch.FloatTensor([1.0,1.0,1.0,1.0,1.0]).cuda()) # 参数为对应长度的梯度初始化\n",
    "#     scores.backward() 必须有参数，因为此时的scores为非标量，为5个元素的向量\n",
    "\n",
    "    # 得到正确分数对应输入图像像素点的梯度\n",
    "    saliency = X_var.grad.data\n",
    "\n",
    "    saliency = saliency.abs() # 取绝对值\n",
    "    saliency, i = torch.max(saliency,dim=1)  # 从3个颜色通道中取绝对值最大的那个通道的数值\n",
    "    saliency = saliency.squeeze() # 去除1维\n",
    "#     print(saliency)\n",
    "\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtorch.utils import load_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = './images/malignant_mass/malignant_mass_1807.png'\n",
    "\n",
    "image = load_image(image_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency_map(image, 0, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/res18_aug_lr_0_001_epoch_250.pth')\n",
    "model.eval()\n",
    "evaluate(model, test_loader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_saliency_map(image, label, model):\n",
    "    from flashtorch.utils import apply_transforms\n",
    "    \n",
    "    input_image = apply_transforms(image)\n",
    "    \n",
    "    saliency_map = compute_saliency_maps(input_image.cuda(), torch.tensor(label).cuda(), model)\n",
    "    saliency_map = saliency_map.cpu().numpy()\n",
    "\n",
    "    plt.imshow(saliency_map)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
